# FloNote V2 â€” Clinical Autofill (Fullâ€‘Stack)

Light, professional, and EMRâ€‘ready clinical note assistant. Dictate â†’ transcribe â†’ structure â†’ export (FHIR/CCDA).

## Features
- ğŸ¤ **Mic capture** with browser MediaRecorder
- ğŸ§  **LLM extraction** (ChatGPT) â†’ SOAP/H&P/Progress sections
- ğŸ§© **Conditionâ€‘aware templates** (COPD, DM2, CHF, Asthma)
- ğŸ“¦ **Export**: FHIR Bundle (JSON) & CCDA (XML)
- ğŸ–¥ï¸ **Sleek UI**: light theme, responsive, dragâ€‘andâ€‘drop reorder
- ğŸ” Ready for SSO & roleâ€‘based auth (hooks in code)

## Quick Start (Local)
```bash
python -m venv .venv && source .venv/bin/activate   # (Windows: .venv\Scripts\activate)
pip install -r requirements.txt

# set OpenAI key
export OPENAI_API_KEY=sk-...                         # (Windows PowerShell: $env:OPENAI_API_KEY="...")

# run api
uvicorn backend.app:app --reload
```

Open `public/index.html` in your browser for the landing/UX. API defaults to `http://localhost:8000`.

## Deploy to Render
- **Build command:** `pip install -r requirements.txt`
- **Start command:** `uvicorn backend.app:app --host 0.0.0.0 --port $PORT`
- **Env:** `OPENAI_API_KEY` (required for live extraction)

## Endpoints
- `POST /api/extract` â†’ `{ transcript, demographics?, problems? }` â†’ structured note
- `POST /api/export/fhir` â†’ FHIR Bundle (JSON)
- `POST /api/export/ccda` â†’ CCDA (XML)
- `GET /api/templates` / `POST /api/templates` â†’ manage templates

## Notes
- This sample uses OpenAI's `Responses` API format when available, and falls back to a ruleâ€‘based parser if no key is present (for demos).
- Replace stub auth with your SSO/IDP (Okta/Auth0) when going live.